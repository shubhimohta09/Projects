{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "###########################################     CAR COUNT >> 200  ########################################################\n",
        "\n",
        "#IMPORTING LIBRARIES\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# OPENING THE VIDEO FILE\n",
        "video_capture = cv2.VideoCapture('trafficsort.mp4')\n",
        "\n",
        "# INITIALIZING THE BACKGROUND SUBTRACTOR AND CAR COUNTER\n",
        "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
        "car_counter = 0\n",
        "\n",
        "# READING THE VIDEO FRAME BY FRAME\n",
        "while True:\n",
        "    ret, frame = video_capture.read()\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # APPLYING BACKGROUND SUBTRATION\n",
        "    fgmask = fgbg.apply(frame)\n",
        "\n",
        "    # REMOVING NOISE AND SMOOTHING THE MASK\n",
        "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel=np.ones((6, 6), np.uint8))\n",
        "\n",
        "    # FINDING CONTOURS IN THE MASK\n",
        "    contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "\n",
        "    #DRAWING BOUNDING BOXES AROUND DETCTED CONTOURS\n",
        "    for contour in contours:\n",
        "        if cv2.contourArea(contour) > 2000:  # ADJUSTING THE CONTOUR AREA AS PER THE DESIRED OUTPUT\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "            car_counter += 1\n",
        "\n",
        "    # ADDING THE CAR COUNTER TO THE FRAME OF THE VIDEO\n",
        "    cv2.putText(frame, f'Car Count: {car_counter}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "    # DISPLAYING THE OUTPUT VIDEO\n",
        "    cv2.imshow('Car Detection', frame)\n",
        "\n",
        "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()\n",
        "######################################################## CAR COUNT >> 200 ################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "################################################# CONGESTED == FAILURE ########################################################\n",
        "\n",
        "# IMPORTING NECESSARY LIBRARIES\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# CREATING A LINE AS A BOUNDARY TO COUNT CARS\n",
        "counting_line = 500  # LINE POSITION CAN BE ADJUSTED AS NEEDED\n",
        "\n",
        "# INITIALIZING THE CAR COUNT AND A SET CAR_ID THAT STORES THE DETECTED CARS \n",
        "car_count = 0\n",
        "car_ids = set()\n",
        "\n",
        "# OPENING THE VIDEO FILE\n",
        "video_capture = cv2.VideoCapture('trafficsort.mp4')\n",
        "\n",
        "# INITIALIZING THE BACKGROUND SUBTRACTOR\n",
        "fgbg = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=120, detectShadows=False)\n",
        "\n",
        "while True:\n",
        "    ret, frame = video_capture.read()\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # APPLYING BACKGROUND SUBTRACTOR\n",
        "    fgmask = fgbg.apply(frame)\n",
        "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel=np.ones((8, 8), np.uint8))\n",
        "\n",
        "    # FINDING THE CONTOURS IN THE MASK\n",
        "    contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    for contour in contours:\n",
        "        if cv2.contourArea(contour) > 8000: # ADJUSTING THE CONTOUR AREA AS PER REQUIRMNETS \n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "            # CHECK IF THE OBJECTS CROUSING THE LINE HAVE BEEN COUNTED\n",
        "            if y + h > counting_line and id(contour) not in car_ids:\n",
        "                car_count += 1\n",
        "                car_ids.add(id(contour)) #MARK THE OBJECT AS COUNTED\n",
        "\n",
        "            # PLOTTING THE BOUNDING BOX AROUND DETECTED CARS\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "\n",
        "    #DRAWING THE LINE IN THE FRAME\n",
        "    cv2.line(frame, (0, counting_line), (frame.shape[1], counting_line), (0, 0, 255), 2)\n",
        "\n",
        "    #INITIALISING A LIST TO STORE THE BOUNDING BOXES THAT ARE PLOTTED\n",
        "    d=[]\n",
        "    d.append(cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)) #APPENDING THOSE BOXES IN THE LIST\n",
        "\n",
        "    #DEFINING THE CONGESTION DENSITY AND THE THRESHOLD FOR THE CONGESTION TO DEFINE ROAD AS CONGESTED OR NOT CONGESTED\n",
        "    congestion_density = len(d)\n",
        "    congestion_threshold = 40\n",
        "\n",
        "    #SETTING A CONDITION TO CLASSIFY THE ROAD IN THE FOOTAGE AS CONGESTED OR NOT CONGESTED\n",
        "    if congestion_density > congestion_threshold:\n",
        "        congestion_status = \"Congested\"\n",
        "        frame = cv2.putText(frame, f\"Congestion: {congestion_status}\", (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "    else:\n",
        "        congestion_status = \"Not Congested\"\n",
        "        frame = cv2.putText(frame, f\"Congestion: {congestion_status}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "\n",
        "    cv2.imshow('Car Detection', frame)\n",
        "\n",
        "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "############################################FINAL CODE############################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "###################################################  FINAL IOT PROJECT(YOLO)  ###########################################################\n",
        "\n",
        "#IMPORTING NECESSARY LIBRARIES\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# LOADING THE YOLO MODEL\n",
        "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
        "\n",
        "# LOADING THE FILE WITH CLASSES\n",
        "with open(\"coco128.yaml\", \"r\") as f:\n",
        "\n",
        "    classes = f.read().strip().split(\"\\n\")\n",
        "\n",
        "# OPENING THE VIDEO FILE AND READING THE FILE FRAME BY FRAME\n",
        "video_capture = cv2.VideoCapture('traffic.mp4')\n",
        "\n",
        "while True:\n",
        "    ret, frame = video_capture.read()\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # PERFORMING OBJECT DETECTION\n",
        "    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False) #CONVERTS A FRAME INTO A BLOB FOR COMPATIBILTY WITH DNN\n",
        "    net.setInput(blob) #PREPROCESSES THESE FRAMES OR BLOBS\n",
        "    outs = net.forward(net.getUnconnectedOutLayersNames()) #PREPROCESSES THE BLOBS AND STORED THE PROCESSED FRAMES IN THE OUTS VARIABLE\n",
        "\n",
        "    # ANALYSING THE DETECTIONS AND DRAWING BOUNDING BOXES\n",
        "    conf_threshold = 0.3 #CONFIDENCE THRESHOLD (THE CONTOURS BELOW THIS THRESHOLD WILL BE IGNORED)\n",
        "    nms_threshold = 0.5\n",
        "    boxes = []\n",
        "    for out in outs: #ITERATES OVER EACH OUTPUT FRAME\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > conf_threshold:\n",
        "                center_x, center_y, width, height = (detection[0:4] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]]))\n",
        "                x, y = int(center_x - width / 2), int(center_y - height / 2)\n",
        "                boxes.append([x, y, int(width), int(height)])\n",
        "\n",
        "    # DRAWING BOUNDING BOXES ON THE VIDEO FRAME\n",
        "    for box in boxes:\n",
        "        x, y, w, h = box\n",
        "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "    #DEFINING THE CINGESTION DENSITY AND IT'S THRESHOLD TO CLASSIFY THE ROAD IN THE FOOTAGE AS CONGESTED OR NOT CONGESTED\n",
        "    crowd_density = len(boxes) #DENSITY IS EQUAL TO THE NUMBER OF BOXES PLOTTED OR THE NUMBER PF CARS DETECTED ON THE ROAD\n",
        "    congestion_threshold = 40  #THRESHOLD SET TO 40 BOUNDING BOXES .I.E. 40 DETECTED CARS ON A ROAD\n",
        "\n",
        "    #SETTING A CONDITION TO CLASSIFY THE ROAD IN THE VIDEO AS CONGESTED OR NOT CONGESTED\n",
        "    if crowd_density > congestion_threshold:\n",
        "        congestion_status = \"Congested\"\n",
        "        frame = cv2.putText(frame, f\"Congestion: {congestion_status}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "    else:\n",
        "        congestion_status = \"Not Congested\"\n",
        "        frame = cv2.putText(frame, f\"Congestion: {congestion_status}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "    #DISPLAYING THE FINAL OUTPUT FRAME\n",
        "    cv2.imshow(\"Object Detection\", frame)\n",
        "\n",
        "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "#SENDING A BROADCAST MESSAGE USING WHATSAPP TO USERS IF THE ROAD IS CONGESTED USING PYWHATKIT LIBRARY\n",
        "import pywhatkit\n",
        "lst=['+918779790683','+917223006950']\n",
        "for i in lst:\n",
        "     if congestion_status == 'Congested':\n",
        "        pywhatkit.sendwhatmsg_instantly(i,\"The road:XYZ is congested, if you are planning to travel through this route, you are advised to take an alternate path to avoid congestion\",4,True,4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
